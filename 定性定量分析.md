### 故事

*某天，面试官：“解释一下std::sort的实现，定性定量的分析一下快排的平均时间复杂度 。”*

*我：“$O(n \log n)$......不会”*

### 定性定量

*GPT说：*

**定性**和**定量**分析的区别可以简单理解为：

- **定性分析**：强调直观的、非数学的理解和解释，通常通过图示、类比、口头描述等手段来展示算法的运行特点。例如，用树状结构来展示快速排序的分治过程。
- **定量分析**：通过数学推导或公式来进行精确计算和证明。它涉及到时间复杂度、空间复杂度等方面的数学分析，通常用来证明算法的效率。例如，使用递归关系来推导快速排序的时间复杂度$O(n \log n)$ 或使用期望值来计算平均情况的复杂度。

因此，可以理解为：

- **定性**是“直观上的解释”；
- **定量**是“通过证明或数学分析的严密解释”。



### 快排的平均复杂度的定性分析

理解为二叉树：

![Capture_20240912_233556](C:\Users\33797\Downloads/Capture_20240912_233556.jpg)

每层要遍历一遍数组划分数组。

理想情况有$\log_2 n$层。最好复杂度$O(n\log n)$。

![Capture_20240912_233943](C:\Users\33797\Downloads/Capture_20240912_233943.jpg)

假设按按一定比例划分数组，最后的二叉树是倾斜的，但是我们能看到最大深度也是$O(\log n)$级别的，所以按某种比例划分复杂度也是$O(n\log n)$的级别。

那么我们可以把随机情况当作是按比例划分的组合复杂度应该也是$O(n\log n)$。



另一方面，划分可能是“好”的或者“差”，如果交替的出现，两次可以“混合”为一次“好”的划分。所以复杂度也是$O(n\log n)$。



### 快排的平均复杂度的定量分析

观察快排的流程

```cpp
快排(区间l,r)：
    选择一个主元素,遍历 比较 (l,r)的每个元素,划分为两个区间(l,mid-1),(mid+1,r)
    递归快排(l,mid-1),快排(mid+1,r)
```

首先，我们分析快排的复杂度依赖于比较次数。

对于第 $i$ 个数于第 $j$ 数最多比一次。

(只用主元素与其他元素比较一次，然后被划分成 $(l,mid-1)，mid， (mid+1,r)$ 三部分，也就是说 $i$ 或 $j$ 选为主元后会与其他元素遍历一遍就排好了。)

$X_{i,j}$ 表示 第 $i$ 个元素与第 $j$ 个元素 是否比较 {0、1}。$X$表示总共比较的次数。

1. $X=\sum_{i=1}^{n-1} \sum_{j=i+1}^{n} X_{i,j}$
2. $E(X)=\sum_{i=1}^{n-1} \sum_{j=i+1}^{n} E(X_{i,j})$
3. $E(X_{i,j})=第i个元素与第j个元素比较的期望$

**第 $i$ 个元素与第 $j$ 个元素比较的期望 :**  怎么算呢？（别人说是  $\frac{2}{|j-i+1|}$,最后我发现不能这么理解，但是思路上确实要计算“第 $i$ 个元素与第 $j$ 个元素比较的期望”，所以保留了这个过程。）

我们计算第 $i$ 大的元素与第 $j$ 大的元素进行比较期望：

情况如下： 

第 $i$ 大的元素与第 $j$ 大的元素之外的元素被某一步被选为主元素，$i$  和 $j$ 会被分到同一未处理部分。

直到：

1. 第 $i$ 大的元素与第 $j$ 大的元素之间的元素被某一步被选为主元素，$i$  和 $j$ 会被分到两未处理部分，不会发生比较。
2. 第 $i$ 大的元素或第 $j$ 大的元素被某一步被选为主元素，发生一次比较。

所以第 $i$ 大的元素与第 $j$ 大的元素比较的期望为 $\frac{2}{|j-i+1|}$

我们把$X_{i,j}$ 重新表示为表示第 $i$ 大的元素与第 $j$ 大的元素是否比较 {0、1}。

所以:

​	$E(X)=\sum_{i=1}^{n-1} \sum_{j=i+1}^{n} {\frac{2}{|j-i+1|}}$

令 $k=j-i$ :

​	$E(X)=\sum_{i=1}^{n-1} \sum_{k=1}^{n-i} {\frac{2}{|k+1|}}$

根据调和级数

​	$ H_n = \sum_{k=1}^{n} \frac{1}{k} \approx \ln n + \gamma $

其中 $( \gamma \approx 0.57721 )$ 为欧拉-马歇罗尼常数。

1.  $E(X) = 2 \sum_{i=1}^{n-1} (\ln(n-i) + \gamma - 1)$
2. $E(X) \approx 2(n \ln n - n + \gamma n)$                           (当 n 较大时，这一部分可以近似为 $n \ln n$)

所以$E(X) = O(n\log n)$